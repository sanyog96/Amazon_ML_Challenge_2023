{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d4fafc-5a75-4666-9f94-1755aa50343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"./data/dataset/train.csv\"\n",
    "TEST_DATA_PATH = \"./data/dataset/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20685645-9a84-424a-81ca-aa997f5fd5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1925202</td>\n",
       "      <td>artzfolio tulip flowers blackout curtain for d...</td>\n",
       "      <td>luxurious appealing: beautiful custom to made ...</td>\n",
       "      <td>missing</td>\n",
       "      <td>1650</td>\n",
       "      <td>2125.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2673191</td>\n",
       "      <td>marks spencer girls pyjama sets t862561c navy ...</td>\n",
       "      <td>harry potter hedwig pyjamas 6 to 16 yrs100% co...</td>\n",
       "      <td>missing</td>\n",
       "      <td>2755</td>\n",
       "      <td>393.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>priknik horn red electric air horn compressor ...</td>\n",
       "      <td>loud dual tone trumpet horn compatible with sx...</td>\n",
       "      <td>specifications: color: red material: aluminium...</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>alishah womens cotton ankle length leggings co...</td>\n",
       "      <td>made by 95%cotton and 5% lycra which gives you...</td>\n",
       "      <td>aishah womens lycra cotton ankel leggings. bra...</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283658</td>\n",
       "      <td>the united empire loyalists: a chronicle of th...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>6112</td>\n",
       "      <td>598.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249693</th>\n",
       "      <td>2422167</td>\n",
       "      <td>nike womens as w ny df swsh hn kh bra cz7610 t...</td>\n",
       "      <td>material : polyester</td>\n",
       "      <td>missing</td>\n",
       "      <td>3009</td>\n",
       "      <td>1181.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249694</th>\n",
       "      <td>2766635</td>\n",
       "      <td>3pcs goose game cute cartoon enamel pins funny...</td>\n",
       "      <td>inspiration inspired by the untitled goose gam...</td>\n",
       "      <td>pbbrand: xvieonr pbr pbproduct name: fashion c...</td>\n",
       "      <td>3413</td>\n",
       "      <td>125.984252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249695</th>\n",
       "      <td>1987786</td>\n",
       "      <td>kangroo sweep movement printed wooden wall clo...</td>\n",
       "      <td>dial size: 12 inches in diameterbig clear repr...</td>\n",
       "      <td>wall clocks are very attractive in looks and e...</td>\n",
       "      <td>1574</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249696</th>\n",
       "      <td>1165754</td>\n",
       "      <td>electro voice ekx to brkt15 wall mount bracket...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>592</td>\n",
       "      <td>2900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249697</th>\n",
       "      <td>1072666</td>\n",
       "      <td>skyjacker c7360sp component box for pnc7360pk ...</td>\n",
       "      <td>component box for pnc7360pk4 in. liftincl. fro...</td>\n",
       "      <td>skyjacker c7360sp component box for pnc7360pk ...</td>\n",
       "      <td>7367</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2249698 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRODUCT_ID                                              TITLE   \n",
       "0           1925202  artzfolio tulip flowers blackout curtain for d...  \\\n",
       "1           2673191  marks spencer girls pyjama sets t862561c navy ...   \n",
       "2           2765088  priknik horn red electric air horn compressor ...   \n",
       "3           1594019  alishah womens cotton ankle length leggings co...   \n",
       "4            283658  the united empire loyalists: a chronicle of th...   \n",
       "...             ...                                                ...   \n",
       "2249693     2422167  nike womens as w ny df swsh hn kh bra cz7610 t...   \n",
       "2249694     2766635  3pcs goose game cute cartoon enamel pins funny...   \n",
       "2249695     1987786  kangroo sweep movement printed wooden wall clo...   \n",
       "2249696     1165754  electro voice ekx to brkt15 wall mount bracket...   \n",
       "2249697     1072666  skyjacker c7360sp component box for pnc7360pk ...   \n",
       "\n",
       "                                             BULLET_POINTS   \n",
       "0        luxurious appealing: beautiful custom to made ...  \\\n",
       "1        harry potter hedwig pyjamas 6 to 16 yrs100% co...   \n",
       "2        loud dual tone trumpet horn compatible with sx...   \n",
       "3        made by 95%cotton and 5% lycra which gives you...   \n",
       "4                                                  missing   \n",
       "...                                                    ...   \n",
       "2249693                               material : polyester   \n",
       "2249694  inspiration inspired by the untitled goose gam...   \n",
       "2249695  dial size: 12 inches in diameterbig clear repr...   \n",
       "2249696                                            missing   \n",
       "2249697  component box for pnc7360pk4 in. liftincl. fro...   \n",
       "\n",
       "                                               DESCRIPTION  PRODUCT_TYPE_ID   \n",
       "0                                                  missing             1650  \\\n",
       "1                                                  missing             2755   \n",
       "2        specifications: color: red material: aluminium...             7537   \n",
       "3        aishah womens lycra cotton ankel leggings. bra...             2996   \n",
       "4                                                  missing             6112   \n",
       "...                                                    ...              ...   \n",
       "2249693                                            missing             3009   \n",
       "2249694  pbbrand: xvieonr pbr pbproduct name: fashion c...             3413   \n",
       "2249695  wall clocks are very attractive in looks and e...             1574   \n",
       "2249696                                            missing              592   \n",
       "2249697  skyjacker c7360sp component box for pnc7360pk ...             7367   \n",
       "\n",
       "         PRODUCT_LENGTH  \n",
       "0           2125.980000  \n",
       "1            393.700000  \n",
       "2            748.031495  \n",
       "3            787.401574  \n",
       "4            598.424000  \n",
       "...                 ...  \n",
       "2249693     1181.100000  \n",
       "2249694      125.984252  \n",
       "2249695     1200.000000  \n",
       "2249696     2900.000000  \n",
       "2249697     2000.000000  \n",
       "\n",
       "[2249698 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "def fillMissing(df):\n",
    "    df.TITLE.fillna(value=\"missing\", inplace=True)\n",
    "    df.BULLET_POINTS.fillna(value=\"missing\", inplace=True)\n",
    "    df.DESCRIPTION.fillna(value=\"missing\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.replace('\"\"', ' inch')\n",
    "    text = text.replace('\"', '')\n",
    "    text = text.replace('/p', '')\n",
    "    text = text.replace('/b', '')\n",
    "    text = text.replace('-', ' to ')\n",
    "    text = re.sub(r'[^a-zA-Z0-9.:/\\s%_\"]|(?<=\\d)_(?=\\d)', '', text)\n",
    "    text = text.replace('_', ' ')\n",
    "    splits = text.strip().split(' ')\n",
    "    return u\" \".join([x for x in splits if len(x) >= 1])\n",
    "\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "train_data = fillMissing(train_data)\n",
    "test_data = fillMissing(test_data)\n",
    "\n",
    "# train data\n",
    "train_data[\"TITLE\"] = train_data[\"TITLE\"].apply(lowercase_text)\n",
    "train_data[\"BULLET_POINTS\"] = train_data[\"BULLET_POINTS\"].apply(lowercase_text)\n",
    "train_data[\"DESCRIPTION\"] = train_data[\"DESCRIPTION\"].apply(lowercase_text)\n",
    "\n",
    "train_data[\"TITLE\"] = train_data[\"TITLE\"].apply(normalize_text)\n",
    "train_data[\"BULLET_POINTS\"] = train_data[\"BULLET_POINTS\"].apply(normalize_text)\n",
    "train_data[\"DESCRIPTION\"] = train_data[\"DESCRIPTION\"].apply(normalize_text)\n",
    "\n",
    "# test data\n",
    "test_data[\"TITLE\"] = test_data[\"TITLE\"].apply(lowercase_text)\n",
    "test_data[\"BULLET_POINTS\"] = test_data[\"BULLET_POINTS\"].apply(lowercase_text)\n",
    "test_data[\"DESCRIPTION\"] = test_data[\"DESCRIPTION\"].apply(lowercase_text)\n",
    "\n",
    "test_data[\"TITLE\"] = test_data[\"TITLE\"].apply(normalize_text)\n",
    "test_data[\"BULLET_POINTS\"] = test_data[\"BULLET_POINTS\"].apply(normalize_text)\n",
    "test_data[\"DESCRIPTION\"] = test_data[\"DESCRIPTION\"].apply(normalize_text)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "31516bd6-02cf-4017-bcce-c6b333bc229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "42b1c4d4-e9ce-4811-a75c-612896097ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
    "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6181c35d-fae6-4908-8778-e29187c9fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, meta_df):\n",
    "        \n",
    "        self.df = meta_df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.df.iloc[index]\n",
    "        title = item[\"TITLE\"]\n",
    "        description = item[\"DESCRIPTION\"]\n",
    "        bullets = item[\"BULLET_POINTS\"]\n",
    "        product_type = item[\"PRODUCT_TYPE_ID\"]\n",
    "        product_length = item[\"PRODUCT_LENGTH\"]\n",
    "        return (title, description, bullets, product_type, product_length)\n",
    "    \n",
    "class AmazonTestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, meta_df):\n",
    "        \n",
    "        self.df = meta_df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.df.iloc[index]\n",
    "        title = item[\"TITLE\"]\n",
    "        description = item[\"DESCRIPTION\"]\n",
    "        bullets = item[\"BULLET_POINTS\"]\n",
    "        product_type = item[\"PRODUCT_TYPE_ID\"]\n",
    "        product_id = item[\"PRODUCT_ID\"]\n",
    "        return (title, description, bullets, product_type, product_id)    \n",
    "    \n",
    "dev_dataset = AmazonDataset(train_data)\n",
    "test_dataset = AmazonTestDataset(test_data)\n",
    "\n",
    "train_set_size = int(len(dev_dataset) * 0.8)\n",
    "valid_set_size = len(dev_dataset) - train_set_size\n",
    "\n",
    "train_dataset_full, validation_dataset_full = torch.utils.data.random_split(dev_dataset, [train_set_size, valid_set_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d7130-aa5b-47dd-953f-e84a2a72b751",
   "metadata": {},
   "source": [
    "## Dataset subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "cfc4893e-0fd6-47ef-a3da-c7c7be23c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "sampling_at = 1\n",
    "\n",
    "train_indices = list(range(0, len(train_dataset_full), sampling_at))\n",
    "val_indices = list(range(0, len(validation_dataset_full), sampling_at))\n",
    "\n",
    "train_dataset = Subset(train_dataset_full, train_indices)\n",
    "validation_dataset = Subset(validation_dataset_full, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a13dff0d-520d-4036-83e0-6826cd187c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchtext\n",
    "from torchtext.functional import to_tensor\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "xlmr_base = torchtext.models.XLMR_BASE_ENCODER\n",
    "xlmr_model = xlmr_base.get_model()\n",
    "xlmr_model.eval()\n",
    "xlmr_model = xlmr_model.to(DEVICE)\n",
    "xlmr_transform = xlmr_base.transform()\n",
    "\n",
    "def data_collate(data, data_transform):\n",
    "    title_feats = []\n",
    "    desc_feats = []\n",
    "    bullet_feats = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sample in data:\n",
    "        title_feats.append(sample[0]) #title\n",
    "        desc_feats.append(sample[1]) # desc\n",
    "        bullet_feats.append(sample[2]) #bullets\n",
    "        lengths.append(sample[4])\n",
    "    \n",
    "    title_feats = to_tensor(data_transform(title_feats), padding_value=1)\n",
    "    desc_feats = to_tensor(data_transform(desc_feats), padding_value=1)\n",
    "    bullet_feats = to_tensor(data_transform(bullet_feats), padding_value=1)\n",
    "    lengths = torch.Tensor(lengths).unsqueeze(dim=1)\n",
    "    \n",
    "    title_feats = xlmr_model(title_feats.to(DEVICE)).detach()\n",
    "    desc_feats = xlmr_model(desc_feats.to(DEVICE)).detach()\n",
    "    bullet_feats = xlmr_model(bullet_feats.to(DEVICE)).detach()\n",
    "    \n",
    "    features = torch.cat((title_feats, desc_feats, bullet_feats), dim=1)\n",
    "            \n",
    "    return features, lengths\n",
    "\n",
    "def testData_collate(data, data_transform):\n",
    "    title_feats = []\n",
    "    desc_feats = []\n",
    "    bullet_feats = []\n",
    "    product_ids = []\n",
    "    \n",
    "    for sample in data:\n",
    "        title_feats.append(sample[0]) #title\n",
    "        desc_feats.append(sample[1]) # desc\n",
    "        bullet_feats.append(sample[2]) #bullets\n",
    "        product_ids.append(sample[4])\n",
    "    \n",
    "    title_feats = to_tensor(data_transform(title_feats), padding_value=1)\n",
    "    desc_feats = to_tensor(data_transform(desc_feats), padding_value=1)\n",
    "    bullet_feats = to_tensor(data_transform(bullet_feats), padding_value=1)\n",
    "    # product_ids = torch.Tensor(product_ids)\n",
    "    \n",
    "    title_feats = xlmr_model(title_feats.to(DEVICE)).detach()\n",
    "    desc_feats = xlmr_model(desc_feats.to(DEVICE)).detach()\n",
    "    bullet_feats = xlmr_model(bullet_feats.to(DEVICE)).detach()\n",
    "    \n",
    "    features = torch.cat((title_feats, desc_feats, bullet_feats), dim=1)\n",
    "            \n",
    "    return features, product_ids\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: data_collate(x, xlmr_transform),\n",
    "    num_workers= 0\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: data_collate(x, xlmr_transform)\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: testData_collate(x, xlmr_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c2fa76b7-2146-4ae4-8885-1520022414cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Regressor(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_cell=768, dim_emb=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        # attentive pooling layers\n",
    "        self.embedding = nn.Linear(dim_cell, dim_emb)\n",
    "        self.linear = nn.Linear(dim_emb, 1)\n",
    "        \n",
    "        self.linear2 = nn.Linear(dim_emb, 256)\n",
    "        self.estimateLayer = nn.Linear(256, 1)\n",
    "            \n",
    "    def forward(self, encoder_out):\n",
    "                \n",
    "        embeds = torch.tanh(self.embedding(encoder_out))  # (batch, seg_len, dim_emb)\n",
    "        attn_weights = F.softmax(self.linear(embeds), dim=1)\n",
    "        embeds = torch.sum(embeds * attn_weights, dim=1)\n",
    "        embedding = embeds.div(embeds.norm(p=2, dim=-1, keepdim=True)).unsqueeze(1)\n",
    "        embedding = embedding.squeeze(dim=1)\n",
    "        \n",
    "        out = F.relu(self.linear2(embedding))\n",
    "        estimate = F.relu(self.estimateLayer(out))\n",
    "        \n",
    "        return estimate, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3d17a4d8-65d3-46fb-a34b-6b4cb1706c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Regressor                                [32, 1]                   --\n",
      "├─Linear: 1-1                            [32, 300, 256]            196,864\n",
      "├─Linear: 1-2                            [32, 300, 1]              257\n",
      "├─Linear: 1-3                            [32, 256]                 65,792\n",
      "├─Linear: 1-4                            [32, 1]                   257\n",
      "==========================================================================================\n",
      "Total params: 263,170\n",
      "Trainable params: 263,170\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 8.42\n",
      "==========================================================================================\n",
      "Input size (MB): 29.49\n",
      "Forward/backward pass size (MB): 19.80\n",
      "Params size (MB): 1.05\n",
      "Estimated Total Size (MB): 50.35\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = Regressor(dim_cell=768, dim_emb=256)\n",
    "print(summary(model, input_size=(BATCH_SIZE, 300, 768)))\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "65066ecf-f220-43bb-b2a8-4d82f2fbcc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]),\n",
       " [604373,\n",
       "  1729783,\n",
       "  1871949,\n",
       "  1107571,\n",
       "  624253,\n",
       "  2782548,\n",
       "  1605901,\n",
       "  938007,\n",
       "  708128,\n",
       "  1609597,\n",
       "  500777,\n",
       "  2736605,\n",
       "  2217122,\n",
       "  914243,\n",
       "  408556,\n",
       "  2896817,\n",
       "  172273,\n",
       "  1718,\n",
       "  308161,\n",
       "  148181,\n",
       "  2829284,\n",
       "  1056991,\n",
       "  1167211,\n",
       "  466450,\n",
       "  2195336,\n",
       "  2517255,\n",
       "  2913047,\n",
       "  2794652,\n",
       "  1995489,\n",
       "  2140554,\n",
       "  1938386,\n",
       "  2485380])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_loader))\n",
    "out = model(batch[0].to(DEVICE))[0].detach()\n",
    "out.shape, batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94cee1-f205-4b22-b9dc-900d4842f6ea",
   "metadata": {},
   "source": [
    "## Training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9ecc03e8-da38-47f0-81c1-0e1008b1fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from sklearn import metrics\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optim = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_step(input, target):\n",
    "    output, _ = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def eval_step(input, target):\n",
    "    output, _ = model(input)\n",
    "    loss = loss_fn(output, target).item()\n",
    "    \n",
    "    output = output.cpu().detach().numpy()\n",
    "    target = target.cpu().detach().numpy()\n",
    "    \n",
    "    score = max( 0 , 100*(1-metrics.mean_absolute_percentage_error(target, output)))\n",
    "    return float(loss), float(score)\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_val_batches = 0\n",
    "    total_score = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_loader:\n",
    "            input = batch[0].to(DEVICE)\n",
    "            target = batch[1].to(DEVICE)\n",
    "            loss, score = eval_step(input, target)\n",
    "            total_loss += loss\n",
    "            total_score += score\n",
    "            num_val_batches += 1\n",
    "\n",
    "    return total_loss / num_val_batches, total_score / num_val_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c3aac5b4-6547-47bc-8191-7ab760daa0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [0], loss = [5886537.129166666], Score = [1.3363508383433025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [1], loss = [5853238.023958334], Score = [4.269537130991618]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [2], loss = [5801823.4625], Score = [7.930068174997966]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [3], loss = [5726305.68125], Score = [13.017815748850504]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [4], loss = [5626282.74375], Score = [18.15937678019206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [5], loss = [5493430.6375], Score = [23.096719185511272]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [6], loss = [5374118.044010417], Score = [27.04355796178182]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [7], loss = [5269659.445833334], Score = [30.20431935787201]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [8], loss = [5169950.800260416], Score = [32.9258394241333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [9], loss = [5081459.9215494795], Score = [33.47242976228396]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "SAVE_PATH = \"./chekpoints/\"\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        input = batch[0].to(DEVICE)\n",
    "        target = batch[1].to(DEVICE)\n",
    "        train_loss = train_step(input, target)\n",
    "\n",
    "    loss, score = evaluate()\n",
    "    print(\"Epoch = [{}], loss = [{}], Score = [{}]\".format(e, loss, score))\n",
    "    \n",
    "    # saving checkpoint\n",
    "    torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefc35e-d06a-4e99-adb2-44ce5b06e3d8",
   "metadata": {},
   "source": [
    "## Test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "18cbbcd5-5a20-4025-bf76-3d9ba7f4bd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604373</td>\n",
       "      <td>manuel dhliogravure et de photogravure en reli...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>6142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729783</td>\n",
       "      <td>dcgaring microfiber throw blanket warm fuzzy p...</td>\n",
       "      <td>quality guaranteed: luxury cozy plush polyeste...</td>\n",
       "      <td>bdcgaring throw blanketbrbr bsize chart w x l ...</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871949</td>\n",
       "      <td>i to match auto parts front license plate brac...</td>\n",
       "      <td>front license plate bracket made of plasticdir...</td>\n",
       "      <td>replacement for the following vehicles:2020 le...</td>\n",
       "      <td>7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1107571</td>\n",
       "      <td>pinmart gold plated excellence in service 1 ye...</td>\n",
       "      <td>available as a single item or bulk packed. sel...</td>\n",
       "      <td>our excellence in service lapel pins feature a...</td>\n",
       "      <td>12442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624253</td>\n",
       "      <td>visual mathematics illustrated by the ti to 92...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>6318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734731</th>\n",
       "      <td>921419</td>\n",
       "      <td>casual canine basic hoodie for dogs 16 medium ...</td>\n",
       "      <td>brightly colored pet sweatshirts with authenti...</td>\n",
       "      <td>za6015 16 43 size to see chart below: medium: ...</td>\n",
       "      <td>7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734732</th>\n",
       "      <td>2456362</td>\n",
       "      <td>dive log book: scuba diving logbook for beginn...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734733</th>\n",
       "      <td>841529</td>\n",
       "      <td>axor 39135001 citterio widespread faucet with ...</td>\n",
       "      <td>8 to inch centers1/2 to inch ips inlets9 to in...</td>\n",
       "      <td>39135001 features: to ada compliant. to includ...</td>\n",
       "      <td>10645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734734</th>\n",
       "      <td>1190194</td>\n",
       "      <td>carolines treasures bb1801ds812 halloween bass...</td>\n",
       "      <td>indoor or outdoor aluminum artwork prints8 inc...</td>\n",
       "      <td>features. great for inside or outside these al...</td>\n",
       "      <td>12680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734735</th>\n",
       "      <td>1040810</td>\n",
       "      <td>amsahr 18c1623 lexmark x3530 remanufactured re...</td>\n",
       "      <td>engineered and manufactured under european sta...</td>\n",
       "      <td>our remanufactured replacement lexmark ink car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734736 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PRODUCT_ID                                              TITLE   \n",
       "0           604373  manuel dhliogravure et de photogravure en reli...  \\\n",
       "1          1729783  dcgaring microfiber throw blanket warm fuzzy p...   \n",
       "2          1871949  i to match auto parts front license plate brac...   \n",
       "3          1107571  pinmart gold plated excellence in service 1 ye...   \n",
       "4           624253  visual mathematics illustrated by the ti to 92...   \n",
       "...            ...                                                ...   \n",
       "734731      921419  casual canine basic hoodie for dogs 16 medium ...   \n",
       "734732     2456362  dive log book: scuba diving logbook for beginn...   \n",
       "734733      841529  axor 39135001 citterio widespread faucet with ...   \n",
       "734734     1190194  carolines treasures bb1801ds812 halloween bass...   \n",
       "734735     1040810  amsahr 18c1623 lexmark x3530 remanufactured re...   \n",
       "\n",
       "                                            BULLET_POINTS   \n",
       "0                                                 missing  \\\n",
       "1       quality guaranteed: luxury cozy plush polyeste...   \n",
       "2       front license plate bracket made of plasticdir...   \n",
       "3       available as a single item or bulk packed. sel...   \n",
       "4                                                 missing   \n",
       "...                                                   ...   \n",
       "734731  brightly colored pet sweatshirts with authenti...   \n",
       "734732                                            missing   \n",
       "734733  8 to inch centers1/2 to inch ips inlets9 to in...   \n",
       "734734  indoor or outdoor aluminum artwork prints8 inc...   \n",
       "734735  engineered and manufactured under european sta...   \n",
       "\n",
       "                                              DESCRIPTION  PRODUCT_TYPE_ID  \n",
       "0                                                 missing             6142  \n",
       "1       bdcgaring throw blanketbrbr bsize chart w x l ...             1622  \n",
       "2       replacement for the following vehicles:2020 le...             7540  \n",
       "3       our excellence in service lapel pins feature a...            12442  \n",
       "4                                                 missing             6318  \n",
       "...                                                   ...              ...  \n",
       "734731  za6015 16 43 size to see chart below: medium: ...             7073  \n",
       "734732                                            missing                1  \n",
       "734733  39135001 features: to ada compliant. to includ...            10645  \n",
       "734734  features. great for inside or outside these al...            12680  \n",
       "734735  our remanufactured replacement lexmark ink car...                0  \n",
       "\n",
       "[734736 rows x 5 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8e37a816-143b-4ff9-b55c-b9263a1a07af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                    | 147/22961 [00:25<1:07:18,  5.65it/s]/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n",
      " 36%|█████████████▋                        | 8270/22961 [24:28<43:43,  5.60it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|███████████████████████████████████| 22961/22961 [1:08:00<00:00,  5.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "product_ids = []\n",
    "product_lengths = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input = batch[0].to(DEVICE)\n",
    "        product_id = batch[1]\n",
    "        estimated_out = list(model(input)[0].squeeze(dim=1).cpu().detach().numpy())\n",
    "        \n",
    "        product_ids.extend(product_id)\n",
    "        product_lengths.extend(estimated_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4aa68640-cfe0-48aa-ae67-a22586160403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604373</td>\n",
       "      <td>504.020538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729783</td>\n",
       "      <td>528.867554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871949</td>\n",
       "      <td>527.113770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1107571</td>\n",
       "      <td>528.101379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624253</td>\n",
       "      <td>497.492645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734731</th>\n",
       "      <td>921419</td>\n",
       "      <td>528.607300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734732</th>\n",
       "      <td>2456362</td>\n",
       "      <td>499.727112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734733</th>\n",
       "      <td>841529</td>\n",
       "      <td>528.368958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734734</th>\n",
       "      <td>1190194</td>\n",
       "      <td>528.394165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734735</th>\n",
       "      <td>1040810</td>\n",
       "      <td>528.430176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734736 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PRODUCT_ID  PRODUCT_LENGTH\n",
       "0           604373      504.020538\n",
       "1          1729783      528.867554\n",
       "2          1871949      527.113770\n",
       "3          1107571      528.101379\n",
       "4           624253      497.492645\n",
       "...            ...             ...\n",
       "734731      921419      528.607300\n",
       "734732     2456362      499.727112\n",
       "734733      841529      528.368958\n",
       "734734     1190194      528.394165\n",
       "734735     1040810      528.430176\n",
       "\n",
       "[734736 rows x 2 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data = {\"PRODUCT_ID\" : product_ids, \"PRODUCT_LENGTH\" : product_lengths}\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e25aec80-655d-4632-9394-b40220fe996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_2pm_day2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1a383339-d5f3-4d57-bf32-92750ef761b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(528.9225, 448.62976)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(product_lengths), min(product_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b42c76-6371-427a-9b9e-b91c5a2f742b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
