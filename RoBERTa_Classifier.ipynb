{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c9d4fafc-5a75-4666-9f94-1755aa50343e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9d4fafc-5a75-4666-9f94-1755aa50343e",
        "outputId": "b010350f-4c29-40e4-bd7f-d8d00fa3c622"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "TRAIN_DATA_PATH = \"dataset/train.csv\"\n",
        "TEST_DATA_PATH = \"dataset/test.csv\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e75ae4ae",
      "metadata": {},
      "source": [
        "without bpe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "20685645-9a84-424a-81ca-aa997f5fd5b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "20685645-9a84-424a-81ca-aa997f5fd5b7",
        "outputId": "82ba4ed4-044a-4450-b155-eccfd0d040d2"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m test_data[\u001b[39m\"\u001b[39m\u001b[39mTITLE\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_data[\u001b[39m\"\u001b[39m\u001b[39mTITLE\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(normalize_text)\n\u001b[0;32m     45\u001b[0m test_data[\u001b[39m\"\u001b[39m\u001b[39mBULLET_POINTS\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_data[\u001b[39m\"\u001b[39m\u001b[39mBULLET_POINTS\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(normalize_text)\n\u001b[1;32m---> 46\u001b[0m test_data[\u001b[39m\"\u001b[39m\u001b[39mDESCRIPTION\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_data[\u001b[39m\"\u001b[39;49m\u001b[39mDESCRIPTION\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(normalize_text)\n\u001b[0;32m     48\u001b[0m train_data\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4527\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4528\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4530\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4631\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "Cell \u001b[1;32mIn[2], line 20\u001b[0m, in \u001b[0;36mnormalize_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     18\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[^a-zA-Z0-9.:/\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m%\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]|(?<=\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md)_(?=\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[1;32m---> 20\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m splits \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m splits \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m])\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "\n",
        "def fillMissing(df):\n",
        "    df.TITLE.fillna(value=\"missing\", inplace=True)\n",
        "    df.BULLET_POINTS.fillna(value=\"missing\", inplace=True)\n",
        "    df.DESCRIPTION.fillna(value=\"missing\", inplace=True)\n",
        "    return df\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.replace('\"\"', ' inch')\n",
        "    text = text.replace('\"', '')\n",
        "    text = text.replace('/p', '')\n",
        "    text = text.replace('/b', '')\n",
        "    text = text.replace('-', ' to ')\n",
        "    text = re.sub(r'[^a-zA-Z0-9.:/\\s%_\"]|(?<=\\d)_(?=\\d)', '', text)\n",
        "    text = text.replace('_', ' ')\n",
        "    splits = text.strip().split(' ')\n",
        "    return u\" \".join([x for x in splits if len(x) >= 1])\n",
        "\n",
        "def lowercase_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "train_data = fillMissing(train_data)\n",
        "test_data = fillMissing(test_data)\n",
        "\n",
        "# train data\n",
        "train_data[\"TITLE\"] = train_data[\"TITLE\"].apply(lowercase_text)\n",
        "train_data[\"BULLET_POINTS\"] = train_data[\"BULLET_POINTS\"].apply(lowercase_text)\n",
        "train_data[\"DESCRIPTION\"] = train_data[\"DESCRIPTION\"].apply(lowercase_text)\n",
        "\n",
        "train_data[\"TITLE\"] = train_data[\"TITLE\"].apply(normalize_text)\n",
        "train_data[\"BULLET_POINTS\"] = train_data[\"BULLET_POINTS\"].apply(normalize_text)\n",
        "train_data[\"DESCRIPTION\"] = train_data[\"DESCRIPTION\"].apply(normalize_text)\n",
        "\n",
        "# test data\n",
        "test_data[\"TITLE\"] = test_data[\"TITLE\"].apply(lowercase_text)\n",
        "test_data[\"BULLET_POINTS\"] = test_data[\"BULLET_POINTS\"].apply(lowercase_text)\n",
        "test_data[\"DESCRIPTION\"] = test_data[\"DESCRIPTION\"].apply(lowercase_text)\n",
        "\n",
        "test_data[\"TITLE\"] = test_data[\"TITLE\"].apply(normalize_text)\n",
        "test_data[\"BULLET_POINTS\"] = test_data[\"BULLET_POINTS\"].apply(normalize_text)\n",
        "test_data[\"DESCRIPTION\"] = test_data[\"DESCRIPTION\"].apply(normalize_text)\n",
        "\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c7558a60",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "train_data = pd.read_csv('dataset/bpe_train.csv')\n",
        "test_data = pd.read_csv('dataset/bpe_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "31516bd6-02cf-4017-bcce-c6b333bc229f",
      "metadata": {
        "id": "31516bd6-02cf-4017-bcce-c6b333bc229f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "42b1c4d4-e9ce-4811-a75c-612896097ca4",
      "metadata": {
        "id": "42b1c4d4-e9ce-4811-a75c-612896097ca4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.07M/5.07M [00:02<00:00, 2.13MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/text/xlmr.vocab.pt\" to C:\\Users\\sanyo/.cache\\torch\\hub\\checkpoints\\xlmr.vocab.pt\n",
            "100%|██████████| 4.85M/4.85M [00:02<00:00, 2.45MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchtext.transforms as T\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "padding_idx = 1\n",
        "bos_idx = 0\n",
        "eos_idx = 2\n",
        "max_seq_len = 256\n",
        "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
        "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
        "\n",
        "text_transform = T.Sequential(\n",
        "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
        "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
        "    T.Truncate(max_seq_len - 2),\n",
        "    T.AddToken(token=bos_idx, begin=True),\n",
        "    T.AddToken(token=eos_idx, begin=False),\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6181c35d-fae6-4908-8778-e29187c9fffa",
      "metadata": {
        "id": "6181c35d-fae6-4908-8778-e29187c9fffa"
      },
      "outputs": [],
      "source": [
        "class AmazonDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, meta_df):\n",
        "        \n",
        "        self.df = meta_df\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.df.iloc[index]\n",
        "        title = item[\"TITLE\"]\n",
        "        description = item[\"DESCRIPTION\"]\n",
        "        bullets = item[\"BULLET_POINTS\"]\n",
        "        product_type = item[\"PRODUCT_TYPE_ID\"]\n",
        "        # product_length = item[\"PRODUCT_LENGTH\"]\n",
        "        # return (title, description, bullets, product_type, product_length)\n",
        "        return (title, description, bullets, product_type)\n",
        "    \n",
        "class AmazonTestDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, meta_df):\n",
        "        \n",
        "        self.df = meta_df\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.df.iloc[index]\n",
        "        title = item[\"TITLE\"]\n",
        "        description = item[\"DESCRIPTION\"]\n",
        "        bullets = item[\"BULLET_POINTS\"]\n",
        "        # product_type = item[\"PRODUCT_TYPE_ID\"]\n",
        "        product_id = item[\"PRODUCT_ID\"]\n",
        "        # return (title, description, bullets, product_type, product_id)\n",
        "        return (title, description, bullets, product_id)\n",
        "    \n",
        "dev_dataset = AmazonDataset(train_data)\n",
        "test_dataset = AmazonTestDataset(test_data)\n",
        "\n",
        "train_set_size = int(len(dev_dataset) * 0.8)\n",
        "valid_set_size = len(dev_dataset) - train_set_size\n",
        "\n",
        "train_dataset_full, validation_dataset_full = torch.utils.data.random_split(dev_dataset, [train_set_size, valid_set_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6d7130-aa5b-47dd-953f-e84a2a72b751",
      "metadata": {
        "id": "7e6d7130-aa5b-47dd-953f-e84a2a72b751"
      },
      "source": [
        "## Dataset subsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cfc4893e-0fd6-47ef-a3da-c7c7be23c1c0",
      "metadata": {
        "id": "cfc4893e-0fd6-47ef-a3da-c7c7be23c1c0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "sampling_at = 100\n",
        "\n",
        "train_indices = list(range(0, len(train_dataset_full), sampling_at))\n",
        "val_indices = list(range(0, len(validation_dataset_full), sampling_at))\n",
        "\n",
        "train_dataset = Subset(train_dataset_full, train_indices)\n",
        "validation_dataset = Subset(validation_dataset_full, val_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a13dff0d-520d-4036-83e0-6826cd187c0b",
      "metadata": {
        "id": "a13dff0d-520d-4036-83e0-6826cd187c0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/text/xlmr.base.encoder.pt\" to C:\\Users\\sanyo/.cache\\torch\\hub\\checkpoints\\xlmr.base.encoder.pt\n",
            "100%|██████████| 1.03G/1.03G [09:36<00:00, 1.93MB/s] \n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m xlmr_model \u001b[39m=\u001b[39m xlmr_base\u001b[39m.\u001b[39mget_model()\n\u001b[0;32m     10\u001b[0m xlmr_model\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> 11\u001b[0m xlmr_model \u001b[39m=\u001b[39m xlmr_model\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[0;32m     12\u001b[0m xlmr_transform \u001b[39m=\u001b[39m xlmr_base\u001b[39m.\u001b[39mtransform()\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_collate\u001b[39m(data, data_transform):\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torchtext\n",
        "from torchtext.functional import to_tensor\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "xlmr_base = torchtext.models.XLMR_BASE_ENCODER\n",
        "xlmr_model = xlmr_base.get_model()\n",
        "xlmr_model.eval()\n",
        "xlmr_model = xlmr_model.to(DEVICE)\n",
        "xlmr_transform = xlmr_base.transform()\n",
        "\n",
        "def data_collate(data, data_transform):\n",
        "    title_feats = []\n",
        "    desc_feats = []\n",
        "    bullet_feats = []\n",
        "    type_ids = []\n",
        "    \n",
        "    for sample in data:\n",
        "        print(len(sample))\n",
        "        title_feats.append(sample[0]) #title\n",
        "        desc_feats.append(sample[1]) # desc\n",
        "        bullet_feats.append(sample[2]) #bullets\n",
        "        type_ids.append(sample[3])\n",
        "    \n",
        "    title_feats = to_tensor(data_transform(title_feats), padding_value=1)\n",
        "    desc_feats = to_tensor(data_transform(desc_feats), padding_value=1)\n",
        "    bullet_feats = to_tensor(data_transform(bullet_feats), padding_value=1)\n",
        "    type_ids = torch.Tensor(type_ids).unsqueeze(dim=1)\n",
        "    \n",
        "    title_feats = xlmr_model(title_feats.to(DEVICE)).detach()\n",
        "    desc_feats = xlmr_model(desc_feats.to(DEVICE)).detach()\n",
        "    bullet_feats = xlmr_model(bullet_feats.to(DEVICE)).detach()\n",
        "    \n",
        "    features = torch.cat((title_feats, desc_feats, bullet_feats), dim=1)\n",
        "            \n",
        "    return features, type_ids\n",
        "\n",
        "def testData_collate(data, data_transform):\n",
        "    title_feats = []\n",
        "    desc_feats = []\n",
        "    bullet_feats = []\n",
        "    product_ids = []\n",
        "    \n",
        "    for sample in data:\n",
        "        title_feats.append(sample[0]) #title\n",
        "        desc_feats.append(sample[1]) # desc\n",
        "        bullet_feats.append(sample[2]) #bullets\n",
        "        product_ids.append(sample[3])\n",
        "    \n",
        "    title_feats = to_tensor(data_transform(title_feats), padding_value=1)\n",
        "    desc_feats = to_tensor(data_transform(desc_feats), padding_value=1)\n",
        "    bullet_feats = to_tensor(data_transform(bullet_feats), padding_value=1)\n",
        "    # product_ids = torch.Tensor(product_ids)\n",
        "    \n",
        "    title_feats = xlmr_model(title_feats.to(DEVICE)).detach()\n",
        "    desc_feats = xlmr_model(desc_feats.to(DEVICE)).detach()\n",
        "    bullet_feats = xlmr_model(bullet_feats.to(DEVICE)).detach()\n",
        "    \n",
        "    features = torch.cat((title_feats, desc_feats, bullet_feats), dim=1)\n",
        "            \n",
        "    return features, product_ids\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda x: data_collate(x, xlmr_transform),\n",
        "    num_workers= 0\n",
        ")\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(\n",
        "    dataset=validation_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=lambda x: data_collate(x, xlmr_transform)\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=lambda x: testData_collate(x, xlmr_transform)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2fa76b7-2146-4ae4-8885-1520022414cf",
      "metadata": {
        "id": "c2fa76b7-2146-4ae4-8885-1520022414cf"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, dim_cell=768, dim_emb=512):\n",
        "        super().__init__()\n",
        "        \n",
        "        # attentive pooling layers\n",
        "        self.embedding = nn.Linear(dim_cell, dim_emb)\n",
        "        self.linear = nn.Linear(dim_emb, 1)\n",
        "        \n",
        "        self.linear2 = nn.Linear(dim_emb, 256)\n",
        "        self.estimateLayer = nn.Linear(256, 13421)\n",
        "            \n",
        "    def forward(self, encoder_out):\n",
        "                \n",
        "        embeds = torch.tanh(self.embedding(encoder_out))  # (batch, seg_len, dim_emb)\n",
        "        attn_weights = F.softmax(self.linear(embeds), dim=1)\n",
        "        embeds = torch.sum(embeds * attn_weights, dim=1)\n",
        "        embedding = embeds.div(embeds.norm(p=2, dim=-1, keepdim=True)).unsqueeze(1)\n",
        "        embedding = embedding.squeeze(dim=1)\n",
        "        \n",
        "        out = F.relu(self.linear2(embedding))\n",
        "        estimate = F.softmax(self.estimateLayer(out))\n",
        "        \n",
        "        return estimate, embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d17a4d8-65d3-46fb-a34b-6b4cb1706c7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d17a4d8-65d3-46fb-a34b-6b4cb1706c7f",
        "outputId": "4ced875b-bda0-47c1-ed3c-86ade90674ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.9/dist-packages (1.7.2)\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "Classifier                               [32, 13421]               --\n",
            "├─Linear: 1-1                            [32, 300, 256]            196,864\n",
            "├─Linear: 1-2                            [32, 300, 1]              257\n",
            "├─Linear: 1-3                            [32, 256]                 65,792\n",
            "├─Linear: 1-4                            [32, 13421]               3,449,197\n",
            "==========================================================================================\n",
            "Total params: 3,712,110\n",
            "Trainable params: 3,712,110\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 118.79\n",
            "==========================================================================================\n",
            "Input size (MB): 29.49\n",
            "Forward/backward pass size (MB): 23.24\n",
            "Params size (MB): 14.85\n",
            "Estimated Total Size (MB): 67.58\n",
            "==========================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a3bf318c453b>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  estimate = F.softmax(self.estimateLayer(out))\n"
          ]
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "model = Classifier(dim_cell=768, dim_emb=256)\n",
        "print(summary(model, input_size=(BATCH_SIZE, 300, 768)))\n",
        "\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65066ecf-f220-43bb-b2a8-4d82f2fbcc5d",
      "metadata": {
        "id": "65066ecf-f220-43bb-b2a8-4d82f2fbcc5d"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(test_loader))\n",
        "out = model(batch[0].to(DEVICE))[0].detach()\n",
        "out.shape, batch[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b94cee1-f205-4b22-b9dc-900d4842f6ea",
      "metadata": {
        "id": "7b94cee1-f205-4b22-b9dc-900d4842f6ea"
      },
      "source": [
        "## Training iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ecc03e8-da38-47f0-81c1-0e1008b1fe47",
      "metadata": {
        "id": "9ecc03e8-da38-47f0-81c1-0e1008b1fe47"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from sklearn import metrics\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optim = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def train_step(input, target):\n",
        "    output, _ = model(input)\n",
        "    print(output.shape)\n",
        "    # loss = loss_fn(output, target)\n",
        "    # optim.zero_grad()\n",
        "    # loss.backward()\n",
        "    # optim.step()\n",
        "    # return loss\n",
        "\n",
        "\n",
        "def eval_step(input, target):\n",
        "    output, _ = model(input)\n",
        "    loss = loss_fn(output, target).item()\n",
        "    \n",
        "    output = output.cpu().detach().numpy()\n",
        "    target = target.cpu().detach().numpy()\n",
        "    \n",
        "    score = max( 0 , 100*(1-metrics.mean_absolute_percentage_error(target, output)))\n",
        "    return float(loss), float(score)\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    num_val_batches = 0\n",
        "    total_score = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_loader:\n",
        "            input = batch[0].to(DEVICE)\n",
        "            target = batch[1].to(DEVICE)\n",
        "            loss, score = eval_step(input, target)\n",
        "            total_loss += loss\n",
        "            total_score += score\n",
        "            num_val_batches += 1\n",
        "\n",
        "    return total_loss / num_val_batches, total_score / num_val_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3aac5b4-6547-47bc-8191-7ab760daa0dd",
      "metadata": {
        "id": "c3aac5b4-6547-47bc-8191-7ab760daa0dd"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "SAVE_PATH = \"./chekpoints/\"\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    for batch in train_loader:\n",
        "        input = batch[0].to(DEVICE)\n",
        "        target = batch[1].to(DEVICE)\n",
        "        train_loss = train_step(input, target)\n",
        "\n",
        "    loss, score = evaluate()\n",
        "    print(\"Epoch = [{}], loss = [{}], Score = [{}]\".format(e, loss, score))\n",
        "    \n",
        "    # saving checkpoint\n",
        "    torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fefc35e-d06a-4e99-adb2-44ce5b06e3d8",
      "metadata": {
        "id": "7fefc35e-d06a-4e99-adb2-44ce5b06e3d8"
      },
      "source": [
        "## Test submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18cbbcd5-5a20-4025-bf76-3d9ba7f4bd67",
      "metadata": {
        "id": "18cbbcd5-5a20-4025-bf76-3d9ba7f4bd67",
        "outputId": "12eb4359-1de4-43e6-a598-43611138ac0c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>BULLET_POINTS</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>PRODUCT_TYPE_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>604373</td>\n",
              "      <td>manuel dhliogravure et de photogravure en reli...</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>6142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1729783</td>\n",
              "      <td>dcgaring microfiber throw blanket warm fuzzy p...</td>\n",
              "      <td>quality guaranteed: luxury cozy plush polyeste...</td>\n",
              "      <td>bdcgaring throw blanketbrbr bsize chart w x l ...</td>\n",
              "      <td>1622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1871949</td>\n",
              "      <td>i to match auto parts front license plate brac...</td>\n",
              "      <td>front license plate bracket made of plasticdir...</td>\n",
              "      <td>replacement for the following vehicles:2020 le...</td>\n",
              "      <td>7540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1107571</td>\n",
              "      <td>pinmart gold plated excellence in service 1 ye...</td>\n",
              "      <td>available as a single item or bulk packed. sel...</td>\n",
              "      <td>our excellence in service lapel pins feature a...</td>\n",
              "      <td>12442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>624253</td>\n",
              "      <td>visual mathematics illustrated by the ti to 92...</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>6318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734731</th>\n",
              "      <td>921419</td>\n",
              "      <td>casual canine basic hoodie for dogs 16 medium ...</td>\n",
              "      <td>brightly colored pet sweatshirts with authenti...</td>\n",
              "      <td>za6015 16 43 size to see chart below: medium: ...</td>\n",
              "      <td>7073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734732</th>\n",
              "      <td>2456362</td>\n",
              "      <td>dive log book: scuba diving logbook for beginn...</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734733</th>\n",
              "      <td>841529</td>\n",
              "      <td>axor 39135001 citterio widespread faucet with ...</td>\n",
              "      <td>8 to inch centers1/2 to inch ips inlets9 to in...</td>\n",
              "      <td>39135001 features: to ada compliant. to includ...</td>\n",
              "      <td>10645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734734</th>\n",
              "      <td>1190194</td>\n",
              "      <td>carolines treasures bb1801ds812 halloween bass...</td>\n",
              "      <td>indoor or outdoor aluminum artwork prints8 inc...</td>\n",
              "      <td>features. great for inside or outside these al...</td>\n",
              "      <td>12680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734735</th>\n",
              "      <td>1040810</td>\n",
              "      <td>amsahr 18c1623 lexmark x3530 remanufactured re...</td>\n",
              "      <td>engineered and manufactured under european sta...</td>\n",
              "      <td>our remanufactured replacement lexmark ink car...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>734736 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        PRODUCT_ID                                              TITLE   \n",
              "0           604373  manuel dhliogravure et de photogravure en reli...  \\\n",
              "1          1729783  dcgaring microfiber throw blanket warm fuzzy p...   \n",
              "2          1871949  i to match auto parts front license plate brac...   \n",
              "3          1107571  pinmart gold plated excellence in service 1 ye...   \n",
              "4           624253  visual mathematics illustrated by the ti to 92...   \n",
              "...            ...                                                ...   \n",
              "734731      921419  casual canine basic hoodie for dogs 16 medium ...   \n",
              "734732     2456362  dive log book: scuba diving logbook for beginn...   \n",
              "734733      841529  axor 39135001 citterio widespread faucet with ...   \n",
              "734734     1190194  carolines treasures bb1801ds812 halloween bass...   \n",
              "734735     1040810  amsahr 18c1623 lexmark x3530 remanufactured re...   \n",
              "\n",
              "                                            BULLET_POINTS   \n",
              "0                                                 missing  \\\n",
              "1       quality guaranteed: luxury cozy plush polyeste...   \n",
              "2       front license plate bracket made of plasticdir...   \n",
              "3       available as a single item or bulk packed. sel...   \n",
              "4                                                 missing   \n",
              "...                                                   ...   \n",
              "734731  brightly colored pet sweatshirts with authenti...   \n",
              "734732                                            missing   \n",
              "734733  8 to inch centers1/2 to inch ips inlets9 to in...   \n",
              "734734  indoor or outdoor aluminum artwork prints8 inc...   \n",
              "734735  engineered and manufactured under european sta...   \n",
              "\n",
              "                                              DESCRIPTION  PRODUCT_TYPE_ID  \n",
              "0                                                 missing             6142  \n",
              "1       bdcgaring throw blanketbrbr bsize chart w x l ...             1622  \n",
              "2       replacement for the following vehicles:2020 le...             7540  \n",
              "3       our excellence in service lapel pins feature a...            12442  \n",
              "4                                                 missing             6318  \n",
              "...                                                   ...              ...  \n",
              "734731  za6015 16 43 size to see chart below: medium: ...             7073  \n",
              "734732                                            missing                1  \n",
              "734733  39135001 features: to ada compliant. to includ...            10645  \n",
              "734734  features. great for inside or outside these al...            12680  \n",
              "734735  our remanufactured replacement lexmark ink car...                0  \n",
              "\n",
              "[734736 rows x 5 columns]"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e37a816-143b-4ff9-b55c-b9263a1a07af",
      "metadata": {
        "id": "8e37a816-143b-4ff9-b55c-b9263a1a07af",
        "outputId": "ebe5f894-359a-4cc1-c2f2-8bf1c6b3b111"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏                                    | 147/22961 [00:25<1:07:18,  5.65it/s]/home/akhil/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py:1282: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
            "  warnings.warn(\n",
            " 36%|█████████████▋                        | 8270/22961 [24:28<43:43,  5.60it/s]IOPub message rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "100%|███████████████████████████████████| 22961/22961 [1:08:00<00:00,  5.63it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "product_ids = []\n",
        "product_lengths = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        input = batch[0].to(DEVICE)\n",
        "        product_id = batch[1]\n",
        "        estimated_out = list(model(input)[0].squeeze(dim=1).cpu().detach().numpy())\n",
        "        \n",
        "        product_ids.extend(product_id)\n",
        "        product_lengths.extend(estimated_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa68640-cfe0-48aa-ae67-a22586160403",
      "metadata": {
        "id": "4aa68640-cfe0-48aa-ae67-a22586160403",
        "outputId": "26c4d12a-5f69-48a5-e23a-1cb3cbc4ee2d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>PRODUCT_LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>604373</td>\n",
              "      <td>504.020538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1729783</td>\n",
              "      <td>528.867554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1871949</td>\n",
              "      <td>527.113770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1107571</td>\n",
              "      <td>528.101379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>624253</td>\n",
              "      <td>497.492645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734731</th>\n",
              "      <td>921419</td>\n",
              "      <td>528.607300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734732</th>\n",
              "      <td>2456362</td>\n",
              "      <td>499.727112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734733</th>\n",
              "      <td>841529</td>\n",
              "      <td>528.368958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734734</th>\n",
              "      <td>1190194</td>\n",
              "      <td>528.394165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734735</th>\n",
              "      <td>1040810</td>\n",
              "      <td>528.430176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>734736 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        PRODUCT_ID  PRODUCT_LENGTH\n",
              "0           604373      504.020538\n",
              "1          1729783      528.867554\n",
              "2          1871949      527.113770\n",
              "3          1107571      528.101379\n",
              "4           624253      497.492645\n",
              "...            ...             ...\n",
              "734731      921419      528.607300\n",
              "734732     2456362      499.727112\n",
              "734733      841529      528.368958\n",
              "734734     1190194      528.394165\n",
              "734735     1040810      528.430176\n",
              "\n",
              "[734736 rows x 2 columns]"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission_data = {\"PRODUCT_ID\" : product_ids, \"PRODUCT_LENGTH\" : product_lengths}\n",
        "submission_df = pd.DataFrame(submission_data)\n",
        "\n",
        "submission_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25aec80-655d-4632-9394-b40220fe996d",
      "metadata": {
        "id": "e25aec80-655d-4632-9394-b40220fe996d"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv('submission_2pm_day2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a383339-d5f3-4d57-bf32-92750ef761b7",
      "metadata": {
        "id": "1a383339-d5f3-4d57-bf32-92750ef761b7",
        "outputId": "468626d7-56bd-4f1e-eb30-3fc9d6c29dab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(528.9225, 448.62976)"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(product_lengths), min(product_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b42c76-6371-427a-9b9e-b91c5a2f742b",
      "metadata": {
        "id": "a8b42c76-6371-427a-9b9e-b91c5a2f742b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
